# Arquitectura v0 (Agentic RAG) – borrador ampliado

## 1) Objetivo
Construir un agente conversacional para el Dpto. de IA (UPM) que permita consultar información principalmente desde PDFs (learning guides) y otras fuentes oficiales (p. ej. fichas de profesores, FAQs institucionales), con énfasis en:
- Respuestas **fundamentadas** (grounded) en evidencias.
- Control de calidad y seguridad (privacidad, “no alucinar”).
- Un enfoque **agent-based**: el sistema decide acciones (buscar, filtrar, pedir aclaración, citar, rechazar, etc.) mediante un grafo de decisiones.

## 2) Principio rector: “Agente que actúa, no solo responde”
En vez de “un LLM + retrieval fijo”, se propone un **orquestador tipo agente** que:
- Identifica intención y contexto (curso, año, profesor, normativa).
- Decide si:
  - Recupera información (RAG),
  - Reescribe la consulta,
  - Pide aclaraciones mínimas,
  - Rechaza por falta de permisos o por solicitud sensible,
  - Devuelve respuesta directa cuando es seguro.
- Aplica **reglas**: *“no afirmes nada sin cita”*, *“si no hay evidencia, di no encontrado”*.

## 3) Vista general (componentes)

### 3.1 Frontend / UI
- Chat web simple.
- Elementos de UX recomendados:
  - Selectores: curso / año / idioma (si se dispone).
  - Botón “Ver fuentes” (citas a secciones/páginas).
  - Mensajes de aclaración guiada (“¿De qué curso y año?”).

### 3.2 Backend API
- Endpoint principal `/chat`.
- Endpoint de ingestión/admin `/ingest` (si aplica).
- Endpoint de evaluación offline `/eval` (batch).

### 3.3 Orquestador Agente (núcleo)
- Implementado como **grafo de estados** (Agent Graph), no como cadena lineal.
- Responsabilidad: decidir el “siguiente paso” según señales:
  - intención detectada,
  - confianza del retrieval,
  - presencia/ausencia de evidencia,
  - políticas de acceso.
- Ventaja: trazabilidad (por qué se hizo X) + modularidad.

### 3.4 Capa de herramientas (Tools)
El agente no “adivina”; usa herramientas:
- `retrieve_docs(query, filters, top_k)` → devuelve fragmentos + metadata.
- `lookup_professor(name)` → consulta base oficial de profes (si existe).
- `list_courses()` → catálogo base (si existe).
- `policy_check(user, request)` → valida si se puede responder.
- `citation_builder(chunks)` → construye citas en formato consistente.

### 3.5 Conocimiento / Almacenamiento
- **Repositorio de fuentes**:
  - PDFs de learning guides (por curso/año/idioma).
  - Otras fuentes oficiales (web/FAQs/directorio).
- **Índice vectorial** para fragmentos (chunks) + metadata.
- **Metadata store** (opcional) para catálogos/entidades: cursos, profes, años, etc.
- **Logs y trazas** (observabilidad).

## 4) Flujo agentic (end-to-end)

### Paso A: Normalización + detección de intención
Inputs:
- mensaje del usuario,
- contexto de conversación,
- (opcional) rol/permisos.

Acciones:
- detectar si es:
  1) Consulta de curso (temario, evaluación, bibliografía…)
  2) Consulta de profesor (contacto, tutorías…)
  3) Procedimiento/política
  4) Recomendación/orientación (más “conversacional”)
  5) Solicitud sensible (PII / notas / datos personales)

Salida:
- `intent`, `entities` (curso, año, profesor), `risk_flag`.

### Paso B: Policy gate (guardrail)
Antes de recuperar/generar:
- Si es sensible → rechazar o redirigir a canales oficiales.
- Si requiere autenticación y no la hay → pedir login o limitar respuesta.
- Registrar decisión para auditoría.

### Paso C: Planificación (agent planning)
El agente decide el plan mínimo:
- Si faltan entidades (curso/año) → preguntar 1 aclaración.
- Si hay entidades → retrieval con filtros.
- Si es recomendación → retrieval + plantilla de consejo + disclaimers.

### Paso D: Retrieval + verificación
1) Retrieval:
- `retrieve_docs()` con filtros por metadata:
  - `course_id`, `year`, `program`, `language`.
2) Scoring/quality signals:
- ¿top chunk supera umbral de similitud?
- ¿hay evidencia suficiente (>= N chunks relevantes)?
- ¿hay conflicto (chunks contradictorios entre años)?
3) Si el retrieval es débil:
- reescribir query (tool) y reintentar 1 vez,
- o pedir aclaración,
- o responder “no encontrado”.

### Paso E: Generación con evidencias (grounded answer)
Reglas:
- La respuesta debe incluir:
  - resumen breve,
  - lista de puntos clave,
  - citas con `doc + sección/página`,
  - (opcional) “siguientes pasos” (links al PDF).
- Prohibido: inventar datos no soportados por los chunks.

### Paso F: Post-proceso (formato y consistencia)
- Plantillas según intent:
  - “Curso: evaluación”
  - “Curso: bibliografía”
  - “Profesor: contacto”
  - “Procedimiento: …”
- Normalización de nombres (curso/profesor).
- Presentación de citas de forma clara.

### Paso G: Observabilidad
Guardar (anonimizado si procede):
- intent y entidades,
- queries de retrieval,
- top_k chunks seleccionados,
- decisión del agente (grafo),
- métricas de confianza.

## 5) Diseño del grafo del agente (propuesta v0)
Estados (nodos):
1) `ClassifyIntent`
2) `PolicyCheck`
3) `NeedClarification?`
4) `Retrieve`
5) `AssessRetrievalQuality`
6) `RewriteQuery` (opcional, máx 1 intento)
7) `GenerateAnswerWithCitations`
8) `RefuseOrRedirect` (si sensible/no permitido)
9) `Return`

Transiciones clave:
- `ClassifyIntent -> PolicyCheck`
- `PolicyCheck -> RefuseOrRedirect` si riesgo alto
- `PolicyCheck -> NeedClarification?`
- `NeedClarification? -> Return` (pregunta al usuario) si faltan datos
- `Retrieve -> AssessRetrievalQuality`
- `AssessRetrievalQuality -> RewriteQuery` si baja confianza
- `RewriteQuery -> Retrieve`
- `AssessRetrievalQuality -> GenerateAnswerWithCitations` si ok
- `GenerateAnswerWithCitations -> Return`

## 6) Ingesta de PDFs (pipeline)
Objetivo: indexar de forma robusta para consultas por curso/año.

Pasos:
1) Descarga/control de versiones:
- guardar PDFs con naming: `course_id_year_lang.pdf`
2) Extracción:
- texto + (si aplica) tablas (según calidad)
3) Chunking:
- por secciones (si se detectan headers) o tamaño fijo con solape.
4) Metadata:
- `course_id`, `course_name`, `year`, `language`, `program`,
- `section_title`, `page_range`, `source_url`.
5) Embeddings + indexación vectorial.

## 7) Estrategia de grounding y “no alucinar”
- Responder solo si:
  - hay evidencia suficiente,
  - o es conocimiento “operativo” definido (p. ej. “no tengo esa info”).
- Si hay contradicción por años:
  - el agente pide el año o presenta ambos con citas.
- Siempre devolver citas para afirmaciones.

## 8) Seguridad y privacidad (mínimos v0)
- Por defecto, NO indexar:
  - datos personales de alumnos,
  - notas, expedientes, emails no públicos.
- Control de acceso por rol si se requiere (futuro).
- Logs: evitar PII, retención limitada.

## 9) Evaluación
Offline:
- Dataset “gold” de Q&A por curso.
- Métricas:
  - Recall@k del retrieval,
  - % respuestas con citas correctas,
  - tasa de “no encontrado” razonable,
  - tasa de rechazos correctos (PII).
Online (piloto):
- feedback thumbs + reporte de “cita incorrecta”.

## 10) Decisiones abiertas
- Framework: LangGraph vs LlamaIndex agents vs implementación propia.
- Vector DB: FAISS/Chroma/pgvector.
- Hosting: UPM/cloud.
- Autenticación: SSO UPM / tokens.
- Fuentes adicionales: web oficial, directorio, FAQs.
